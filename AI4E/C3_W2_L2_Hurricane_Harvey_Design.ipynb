{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFk_v-dvtG7c"
   },
   "source": [
    "# Lab 2: Image classfication with Convolutional Neural Networks\n",
    "\n",
    "After exploring the Flood Damage Assessment Dataset in the previous notebook, you will apply the Convolutional Neural Networks to classify whether an area is flooded in a satellite image. You will also evaluate the performance of the Convolutional Neural Networks using a confusion matrix and commonly-used evaluation metrics in machine learning research. To make your Convolutional Neural Networks more robust, you will be augmenting the Hurricane Harvey image dataset.\n",
    "\n",
    "In this lab, you will apply the following steps:\n",
    "\n",
    "1. Import packages\n",
    "2. Load the training data \n",
    "3. Augment data \n",
    "4. Load training data with augmentation\n",
    "5. Train your model (load pre-trained model)\n",
    "6. Load the test dataset\n",
    "7. Test your model \n",
    "8. Visualize the results \n",
    "\n",
    "**Note:** In other case studies in this specialization you've started by first establishing a simple baseline for comparison and to see how well you can do without implementing any complex AI solution. In this case, you could try some simple techniques like, for example, just establishing a color threshold to look for the brown flood waters that are common in the images displaying damage. However, when it comes to working with image data, neural networks work very well for a wide variety of tasks. In this lab, you'll train a relatively simple neural network architecture and find that it performs satisfactorily for the task at hand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Python packages and libraries\n",
    "\n",
    "Run the next cell to import that Python packages you'll need for this lab.\n",
    "\n",
    "Note the `import utils` line. This line imports the functions that were specifically written for this lab. If you want to look at what these functions are, go to `File -> Open...` and open the `utils.py` file to have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RXpjSTc82pWh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "\n",
    "# Configure Python to ignore Tensorflow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'    # Ignore tf warning messages\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils\n",
    "\n",
    "print('All packages imported successfully!')\n",
    "IMAGE_SIZE = (150, 150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the training data\n",
    "Now you can load the train data with which you can train your model. Since training on full data would take too long, you will load just a part of data from `train_mini` folder. You can see the full data in the `train` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('data/train_mini', \n",
    "                    target_size = (150, 150),\n",
    "                    batch_size = 128,\n",
    "                    shuffle = True,                           \n",
    "                    class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2cat = {1: 'visible_damage',\n",
    "             0: 'no_damage'}\n",
    "\n",
    "print(label2cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Augment your data\n",
    "Data augmentation can be used to increase the variety of pictures by simulating different conditions which might occur in real-world disasters. It is very important in this lab because the satellite images were collected only for two days in the aftermath of the flooding due to Hurricane Harvey and do not include a lot of variety of conditions. With data augmentation, we can simulate various conditions of illumination or orientations of the satellite.\n",
    "\n",
    "Select a single image. You can change the number of selected image below if you would like to see another image. Let's use this image to illustrate the idea of augmenting your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected image must be an integer between 0 and 31 (inclusive).\n",
    "selected_image = 120\n",
    "\n",
    "images, labels = next(iter(train_generator))\n",
    "image = images[selected_image]\n",
    "label = label2cat[labels[selected_image]]\n",
    "utils.plot_one_image(image, label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Flipping\n",
    "\n",
    "Consider the impact of flipping an image horizontally or vertically. Applying this transformation randomly to an image can generate new variations for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.data_aug_flip(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Zooming\n",
    "\n",
    "To create new images, you can also try zooming in or out of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.data_aug_zoom(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Rotating\n",
    "\n",
    "One method for creating new images is to rotate an existing image around its center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.data_aug_rot(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Changing Brightness\n",
    "\n",
    "Modifying the brightness of an image is another technique that can be used to create new images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.data_aug_brightness(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Combining Different Image Augmentations\n",
    "Nowadays, many AI frameworks provide tools that allow for the application of random augmentations to input images, which can create new examples. In this project, this functionality is implemented using the image data generator. First, you can simulate this process by using Keras preprocessing steps. Try combining various preprocessing steps to gain insight into the types of images that are being fed to your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.data_aug_random(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load the train data with augmentation\n",
    "Now that you have seen how the data augmentation works, you can turn it on in the image data generator. Note how you call the same `ImageDataGenerator` function as in the step 2, but you put additional parameters for data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale = 1./255,\n",
    "                    brightness_range=(0.5, 1.5),\n",
    "                    rotation_range = 30,\n",
    "                    shear_range = 0.2,\n",
    "                    zoom_range = 0.2,\n",
    "                    horizontal_flip = True,\n",
    "                    vertical_flip = True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    'data/train_mini',\n",
    "                    target_size = (150,150),\n",
    "                    batch_size = 32,\n",
    "                    class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load the pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Load the pre-trained model\n",
    "Since the model takes up too much space and time to train here, you will load a pre-trained model. If you are interested in learning more about the code to train the model, check out [Hurricane Harvey Model Training Notebook on GitHub](https://github.com/https-deeplearning-ai/ai-for-good-public/blob/main/Course3/W3/C3_W3_Lab_2_damage_detection_CNN.ipynb).\n",
    "\n",
    "With the cell below, you can load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('models/cnn_100epochs_Adam.hdf5', compile=False)\n",
    "\n",
    "adam = Adam(learning_rate=0.000001) # Small learning rate for fine tuning \n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "print(\"Model has been successfully loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is a neural network (like the one on the image below, but much more complicated).\n",
    "<img src='images/neural_network.jpg'>\n",
    "\n",
    "To understand the model architecture, you can use the `.summary()` which prints out the detailed architecture of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was trained for 100 epochs on the full training set with augmented data. Below you can see some training metrics, showing the accuracy and the binary crossentropy loss on the training and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_training_history('./models/cnn_history')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Perform mini-training\n",
    "To illustrate the training, we created another folder called `train_mini` with a small subset of training data. Because of memory issues it would not be feasible to train the model on full data in this environment, but you can run the training on a reduced dataset for a few epochs below to get a feeling of how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to train the model for three more epochs (this can run for a few minutes)\n",
    "epochs = 3\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have the model, you can load the test set from the 'data/test' folder in order to evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RIanzAez318Y",
    "outputId": "38dcd19f-9abd-4be1-eb62-1802f2c92d0a"
   },
   "outputs": [],
   "source": [
    "test_dataset_dir = './data/test/'\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_dataset_dir, \n",
    "                    target_size = (150, 150),\n",
    "                    batch_size = 128,\n",
    "                    shuffle = False,                           \n",
    "                    class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate the model's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Predict on the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you will load the ground truth labels from your test set and make predictions using the pre-trained CNN Model you just loaded earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = test_generator.classes\n",
    "y_predict_prob_1 = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Get the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you are going to use the confusion matrix to analyze whether each category of your data is classified correctly as \"visible_damage\" or \"no_damage\" using your CNN Model. In the both in the x-axis and y-axis, there are two categories: \"visible_damage\" or \"no_damage\". The x-axis shows the predicted label and the y-axis shows the true label. You will use 0.5 as the threshold for the predictions. When the probablistic prediction of your CNN Model is greater than or equal to 0.5, you will convert the probablistic prediction into \"visible_damage\". In contrast, when the probablistic prediction of your CNN Model is less than 0.5, you will convert the probablistic prediction into \"no_damage\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_confusion_matrix(y_labels, y_predict_prob_1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Evaluation metrics: Accuracy, Precision and Recall\n",
    "You can use accuracy, precision and recall to evaluate the performance of your CNN Model. They are defined as shown in the image below.\n",
    "<img src='images/evaluation_metrics.jpg'>\n",
    "Below you will calculate all three scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall = utils.get_performance_metrics(y_labels, y_predict_prob_1.reshape(-1))\n",
    "\n",
    "print(f'Accuracy:  {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall:    {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize results\n",
    "Now you can start thinking about how to present your results visually. Perhaps a simple meter showing the prediction of the model (probability of damage) would do the trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths, number_of_images = utils.get_some_images('test')\n",
    "\n",
    "utils.interact_with_slider(utils.display_predictions, 0, number_of_images-1, model, label2cat, image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Analyzing misclassified images\n",
    "\n",
    "Now you can check what are some images that were misclassified. In the next cell you first find all the misclassified examples. Then you can look at them using the interactive slider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified = utils.find_misclassified_images(y_labels, y_predict_prob_1, test_generator.filenames, './data/test/')\n",
    "\n",
    "utils.interact_with_slider(utils.display_predictions, 0, len(misclassified)-1, model, label2cat, misclassified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
